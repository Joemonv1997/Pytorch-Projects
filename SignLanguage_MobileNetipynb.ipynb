{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "SignLanguage-MobileNetipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "la4OmUlqQPFR",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "a80f12a4-860c-4523-f5cf-fd726255b14e"
      },
      "source": [
        "from keras.applications import mobilenet\n",
        "import random"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vu4fIMhUQfUp",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        },
        "outputId": "30e7a694-526b-420e-b84f-a51dcc8d0f30"
      },
      "source": [
        "mob=mobilenet.MobileNet()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://github.com/fchollet/deep-learning-models/releases/download/v0.6/mobilenet_1_0_224_tf.h5\n",
            "17227776/17225924 [==============================] - 1s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T1bj6ItAQlI-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import keras\n",
        "X=mob.layers[-6].output\n",
        "output=keras.layers.Dense(10,activation='softmax')(X)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UZHWvoOoVQ3U",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "83e346d4-7712-48f3-ce6c-b2fb6678221d"
      },
      "source": [
        "import os\n",
        "import shutil\n",
        "os.listdir('/content/drive/My Drive/Sign-Language-Digits-Dataset/Dataset/')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['train', 'valid', 'test']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Yot7WVr_T0Km",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "cdc5671a-73d7-4173-f316-b55f3012b744"
      },
      "source": [
        "os.chdir('/content/drive/My Drive/Sign-Language-Digits-Dataset/')\n",
        "if os.path.isdir('/Dataset/train/') is True: \n",
        "    os.mkdir('Dataset/train')\n",
        "    os.mkdir('Dataset/valid')\n",
        "    os.mkdir('Dataset/test')\n",
        "\n",
        "    for i in range(0, 10):\n",
        "        shutil.move(f'Dataset/{i}', f'Dataset/train/{i}')\n",
        "        os.mkdir(f'Dataset/valid/{i}')\n",
        "        os.mkdir(f'Dataset/test/{i}')\n",
        "\n",
        "        valid_samples = random.sample(os.listdir(f'Dataset/train/{i}'), 30)\n",
        "        for j in valid_samples:\n",
        "            shutil.move(f'Dataset/train/{i}/{j}', f'Dataset/valid/{i}')\n",
        "\n",
        "        test_samples = random.sample(os.listdir(f'Dataset/train/{i}'), 5)\n",
        "        for k in test_samples:\n",
        "            shutil.move(f'Dataset/train/{i}/{k}', f'Dataset/test/{i}')\n",
        "else:\n",
        "  print('Already Exist')\n",
        "os.chdir('../..')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Already Exist\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qhJ-2lOnVF9O",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 67
        },
        "outputId": "b3b4ddff-52c8-43dc-ece0-bc8152741838"
      },
      "source": [
        "train_path = '/content/drive/My Drive/Sign-Language-Digits-Dataset/Dataset/train'\n",
        "valid_path = '/content/drive/My Drive/Sign-Language-Digits-Dataset/Dataset/valid'\n",
        "test_path = '/content/drive/My Drive/Sign-Language-Digits-Dataset/Dataset/test'\n",
        "\n",
        "train_batches = keras.preprocessing.image.ImageDataGenerator(preprocessing_function=keras.applications.mobilenet.preprocess_input).flow_from_directory(\n",
        "    directory=train_path, target_size=(224,224), batch_size=10)\n",
        "valid_batches = keras.preprocessing.image.ImageDataGenerator(preprocessing_function=keras.applications.mobilenet.preprocess_input).flow_from_directory(\n",
        "    directory=valid_path, target_size=(224,224), batch_size=10)\n",
        "test_batches = keras.preprocessing.image.ImageDataGenerator(preprocessing_function=keras.applications.mobilenet.preprocess_input).flow_from_directory(\n",
        "    directory=test_path, target_size=(224,224), batch_size=10, shuffle=False)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 1712 images belonging to 10 classes.\n",
            "Found 300 images belonging to 10 classes.\n",
            "Found 50 images belonging to 10 classes.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TwvT0MD3RUZt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model=keras.models.Model(inputs=mob.input, outputs=output)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rUVmPQq5SNmg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for layer in model.layers[:-23]:\n",
        "    layer.trainable = False"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d26465s1TVIN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.compile(optimizer=keras.optimizers.Adam(lr=0.0001), loss='categorical_crossentropy', metrics=['accuracy'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vC4-tTFtTg22",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "c97b79b7-ff74-443c-bf9e-1097a61bd936"
      },
      "source": [
        "model.fit(x=train_batches, steps_per_epoch=len(train_batches),validation_data=valid_batches,validation_steps=len(valid_batches),epochs=30,verbose=1)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/30\n",
            "172/172 [==============================] - 839s 5s/step - loss: 0.8405 - accuracy: 0.7512 - val_loss: 1.3835 - val_accuracy: 0.4333\n",
            "Epoch 2/30\n",
            "172/172 [==============================] - 8s 44ms/step - loss: 0.1802 - accuracy: 0.9720 - val_loss: 1.1309 - val_accuracy: 0.6967\n",
            "Epoch 3/30\n",
            "172/172 [==============================] - 8s 44ms/step - loss: 0.0821 - accuracy: 0.9912 - val_loss: 0.5672 - val_accuracy: 0.8533\n",
            "Epoch 4/30\n",
            "172/172 [==============================] - 7s 44ms/step - loss: 0.0501 - accuracy: 0.9982 - val_loss: 0.8254 - val_accuracy: 0.8067\n",
            "Epoch 5/30\n",
            "172/172 [==============================] - 7s 43ms/step - loss: 0.0370 - accuracy: 0.9965 - val_loss: 0.3139 - val_accuracy: 0.8933\n",
            "Epoch 6/30\n",
            "172/172 [==============================] - 7s 43ms/step - loss: 0.0293 - accuracy: 0.9982 - val_loss: 0.3929 - val_accuracy: 0.8333\n",
            "Epoch 7/30\n",
            "172/172 [==============================] - 8s 44ms/step - loss: 0.0211 - accuracy: 0.9982 - val_loss: 0.5622 - val_accuracy: 0.8933\n",
            "Epoch 8/30\n",
            "172/172 [==============================] - 8s 44ms/step - loss: 0.0181 - accuracy: 0.9982 - val_loss: 0.3157 - val_accuracy: 0.9167\n",
            "Epoch 9/30\n",
            "172/172 [==============================] - 7s 43ms/step - loss: 0.0184 - accuracy: 0.9988 - val_loss: 0.8521 - val_accuracy: 0.8967\n",
            "Epoch 10/30\n",
            "172/172 [==============================] - 8s 44ms/step - loss: 0.0134 - accuracy: 0.9988 - val_loss: 0.4445 - val_accuracy: 0.9000\n",
            "Epoch 11/30\n",
            "172/172 [==============================] - 8s 45ms/step - loss: 0.0071 - accuracy: 1.0000 - val_loss: 0.0336 - val_accuracy: 0.9167\n",
            "Epoch 12/30\n",
            "172/172 [==============================] - 8s 44ms/step - loss: 0.0158 - accuracy: 0.9977 - val_loss: 0.2393 - val_accuracy: 0.9500\n",
            "Epoch 13/30\n",
            "172/172 [==============================] - 8s 44ms/step - loss: 0.0282 - accuracy: 0.9988 - val_loss: 0.5728 - val_accuracy: 0.7800\n",
            "Epoch 14/30\n",
            "172/172 [==============================] - 8s 44ms/step - loss: 0.0224 - accuracy: 0.9982 - val_loss: 0.5265 - val_accuracy: 0.8933\n",
            "Epoch 15/30\n",
            "172/172 [==============================] - 8s 44ms/step - loss: 0.0055 - accuracy: 1.0000 - val_loss: 0.8497 - val_accuracy: 0.8100\n",
            "Epoch 16/30\n",
            "172/172 [==============================] - 8s 45ms/step - loss: 0.0064 - accuracy: 0.9994 - val_loss: 0.3852 - val_accuracy: 0.8500\n",
            "Epoch 17/30\n",
            "172/172 [==============================] - 8s 44ms/step - loss: 0.0047 - accuracy: 1.0000 - val_loss: 0.1079 - val_accuracy: 0.9167\n",
            "Epoch 18/30\n",
            "172/172 [==============================] - 7s 43ms/step - loss: 0.0042 - accuracy: 1.0000 - val_loss: 0.4043 - val_accuracy: 0.9133\n",
            "Epoch 19/30\n",
            "172/172 [==============================] - 8s 44ms/step - loss: 0.0079 - accuracy: 0.9994 - val_loss: 0.5470 - val_accuracy: 0.8900\n",
            "Epoch 20/30\n",
            "172/172 [==============================] - 7s 43ms/step - loss: 0.0264 - accuracy: 0.9988 - val_loss: 0.4064 - val_accuracy: 0.8900\n",
            "Epoch 21/30\n",
            "172/172 [==============================] - 7s 43ms/step - loss: 0.0083 - accuracy: 0.9988 - val_loss: 0.2467 - val_accuracy: 0.9200\n",
            "Epoch 22/30\n",
            "172/172 [==============================] - 8s 45ms/step - loss: 0.0069 - accuracy: 0.9988 - val_loss: 0.0910 - val_accuracy: 0.9433\n",
            "Epoch 23/30\n",
            "172/172 [==============================] - 8s 44ms/step - loss: 0.0030 - accuracy: 1.0000 - val_loss: 0.3145 - val_accuracy: 0.9433\n",
            "Epoch 24/30\n",
            "172/172 [==============================] - 8s 44ms/step - loss: 0.0190 - accuracy: 0.9982 - val_loss: 0.4420 - val_accuracy: 0.7267\n",
            "Epoch 25/30\n",
            "172/172 [==============================] - 8s 44ms/step - loss: 0.0264 - accuracy: 0.9965 - val_loss: 0.1923 - val_accuracy: 0.8967\n",
            "Epoch 26/30\n",
            "172/172 [==============================] - 8s 44ms/step - loss: 0.0063 - accuracy: 0.9994 - val_loss: 0.2464 - val_accuracy: 0.8467\n",
            "Epoch 27/30\n",
            "172/172 [==============================] - 8s 44ms/step - loss: 0.0037 - accuracy: 1.0000 - val_loss: 0.5436 - val_accuracy: 0.9067\n",
            "Epoch 28/30\n",
            "172/172 [==============================] - 8s 44ms/step - loss: 0.0057 - accuracy: 0.9988 - val_loss: 0.0339 - val_accuracy: 0.9267\n",
            "Epoch 29/30\n",
            "172/172 [==============================] - 8s 44ms/step - loss: 0.0063 - accuracy: 0.9988 - val_loss: 0.0546 - val_accuracy: 0.9667\n",
            "Epoch 30/30\n",
            "172/172 [==============================] - 8s 45ms/step - loss: 0.0045 - accuracy: 0.9988 - val_loss: 0.3015 - val_accuracy: 0.9467\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.callbacks.History at 0x7fc6809cbe10>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2aiBd4CfTup8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.save('Signmobile.h5')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tFbQq5Ocoqpn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}